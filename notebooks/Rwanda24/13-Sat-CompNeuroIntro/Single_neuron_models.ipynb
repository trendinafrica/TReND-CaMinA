{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single neuron models\n",
    "By [Marcus Ghosh](profiles.imperial.ac.uk/m.ghosh) & [Dan Goodman](https://neural-reckoning.org/)\n",
    "\n",
    "Based on an exercise from our [Neuro4ML](https://neuro4ml.github.io/) course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/trendinafrica/TReND-CaMinA/tree/main/notebooks/Rwanda24/13-Sat-CompNeuroIntro/Single_neuron_models.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "\n",
    "# For Google Colab\n",
    "if not os.path.exists('Data/test_current.csv'):\n",
    "  !git clone https://github.com/trendinafrica/TReND-CaMinA.git\n",
    "  %cd /content/TReND-CaMinA/notebooks/Rwanda24/13-Sat-CompNeuroIntro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim\n",
    "We're going to code an increasingly detailed model of a single neuron, then test how well this, and other models can approximate the spikes produced by a \"real\" neuron in response to a set of random input currents. This \"real\" neuron is actually just a complex model, but the idea is the same! \n",
    "\n",
    "The notebook is divided into three parts which you should work on together in pairs.  \n",
    "\n",
    "**Model** - we'll start with code for an integrate-and-fire neuron, and add a number of features. \n",
    "\n",
    "**Testing** - we'll test how well this model is able to match data from the \"real\" neuron.\n",
    "\n",
    "Finally, we'll run a friendly **competition** to see which pair can best match the \"real\" neuron's data, using their own models. \n",
    "\n",
    "For the last 30mins of the session, each pair will summarise what they tried and there will be a small prize for the pair with the model which best approximates the \"real\" neuron.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate-and-fire neuron\n",
    "\n",
    "We're going to start by looking at the code for a neuron model which simply integrates it's input's over time, spikes when it reaches a threshold and then resets to a baseline value. \n",
    "\n",
    "We'll define a function (neuron_model) which takes:\n",
    "* ``I`` - a numpy vector, with the input current at every time-step. \n",
    "* ``baseline`` - a float, which sets the baseline membrane potential. By default this will be 0.0.\n",
    "* ``threshold`` - a float, which sets the spiking threshold. By default this will be 1.0.\n",
    "* ``dt`` - a float, which sets the time between discrete simulation steps. As units we'll use milliseconds, and by default will set the time-step to be 0.1 (ms).\n",
    "\n",
    "Our function returns: \n",
    "* ``v`` - a numpy vector, with the output membrane potential at every time-step. \n",
    "* ``Spikes`` - a numpy vector with the recorded spike times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_model(I, baseline=0.0, threshold=1.0, dt=0.1): \n",
    "\n",
    "    time_steps = len(I) # the number of time-steps in the simulation\n",
    "    v = np.ones(time_steps) * baseline # membrane potential  \n",
    "    spikes = [] # a list to store spike times \n",
    "\n",
    "    for time in range(time_steps - 1):\n",
    "        if v[time] > threshold:\n",
    "            spikes.append(time * dt) # record spike time \n",
    "            v[time] = baseline # reset membrane potential \n",
    "        \n",
    "        v[time + 1] = v[time] + I[time]*dt # update membrane potential \n",
    "\n",
    "    return v, np.array(spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how our models behave we'll define a function to plot both the input current (``I``) and how our model responds: ``v`` and ``Spikes``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_response(I, v, spikes, dt=0.1):\n",
    "    plt.plot(np.arange(len(I))*dt, I, color='xkcd:purple', linewidth=2, label='Input current')\n",
    "    plt.plot(np.arange(len(I))*dt, v, color='xkcd:dark seafoam green', linewidth=2, label='Membrane potential')\n",
    "    \n",
    "    for i, t in enumerate(spikes):\n",
    "        plt.axvline(t, c='xkcd:grey', lw=2, label='Spikes' if i==0 else None)\n",
    "\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('V')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll input a random current to our model. \n",
    "\n",
    "As an input we'll load a random current, which was input to our \"real\" neuron. That way we can easily see how each version of our model responds to the same input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_I = np.loadtxt('Data/test_current.csv') # shape (repeats, num_time_steps)\n",
    "I = np.copy(test_I[0, :300]) # we'll use the input from the first repeat, and the first 30ms \n",
    "I[50:100] = 0.0 # to see what our model's do without input, we'll also set the input, over some time-steps, to zero\n",
    "\n",
    "v, spikes = neuron_model(I) # simulate \n",
    "plot_model_response(I, v, spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a refractory period  \n",
    "\n",
    "After spiking, real neurons enter a refractory period - during which they will not spike. \n",
    "\n",
    "One way to model this is to: \n",
    "* Add ``r_timer`` as a parameter to our function. This should be a float (e.g. 0.5) which sets the length of the refractory period (in ms). \n",
    "* Following each spike set a counter (``r_time``) to ``r_timer``. \n",
    "* Then for subsequent time steps, set ``v`` to baseline and decrease the timer by ``dt``, until the timer reaches zero.\n",
    "\n",
    "Copy the neuron model function from above into the cell below, edit it to include a refractory period and then try plotting it's response to the input current above. \n",
    "\n",
    "How does changing the length of the refractory period change the neuron's behaviour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your solution here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are stuck or would like to check your answer you can: \n",
    "# Check Solutions/refractory_period.py  \n",
    "\n",
    "# Or if you are running locally, you can:\n",
    "# Uncomment and run the line below to load the solution.\n",
    "# %load ./Solutions/refractory_period.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model response\n",
    "v, spikes = neuron_model(I) # simulate \n",
    "plot_model_response(I, v, spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a leak  \n",
    "\n",
    "Rather than integrating and retaining their inputs indefinitely, real neuron's leak some current. \n",
    "\n",
    "This means that when they receive little or no input, their membrane potential will tend towards their baseline.\n",
    "\n",
    "Adding this leak will make our model a **leaky** integrate-and-fire neuron. This model's membrane potential changes over time as: \n",
    "\n",
    "$$ \\tau \\frac{dV}{dt} = I(t)-v $$\n",
    "\n",
    "Where:\n",
    "* $ \\tau $ determines the rate of decay.     \n",
    "* $ I(t) $ is the time-varying input current to the neuron. \n",
    "* $ v $ is the neuron's membrane potential. \n",
    "\n",
    "Copy your neuron model function from above into the cell below, then: \n",
    "* Add a parameter ``tau`` - the membrane time constant in ms. E.g. 5.  \n",
    "* Find dV/dt (using the equation above).\n",
    "* Use dV/dt to update the membrane potential. \n",
    "\n",
    "Finally try plotting this model's response to the input current above. \n",
    "\n",
    "How does altering $ \\tau $ change the neuron's behaviour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your solution here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are stuck or would like to check your answer you can: \n",
    "# Check Solutions/leak.py  \n",
    "\n",
    "# Or if you are running locally, you can:\n",
    "# Uncomment and run the line below to load the solution.\n",
    "# %load ./Solutions/leak.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model response\n",
    "scale = 10 # Depending on how you implemented the leak, you may need to scale I to get your model to spike\n",
    "v, spikes = neuron_model(I * scale) # simulate   \n",
    "plot_model_response(I, v, spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a dynamic threshold\n",
    "\n",
    "Many neuron's change their behaviour depending on their own recent activity.\n",
    "\n",
    "For example, in response to constant input they'll spike less and less frequently. \n",
    "\n",
    "One way to model this is to add a dynamic threshold. \n",
    "\n",
    "To do so:\n",
    "* Add a threshold increment parameter ``thr_i`` - following a spike we will increase our threshold by this amount (e.g. 2). \n",
    "* Add a threshold decay parameter ``thr_tau`` - at every time time-step we'll use this value (e.g. 50) to decay our threshold back to it's starting value (``threshold``)  \n",
    "\n",
    "Again, copy your neuron model function from above, edit the code and then try plotting your model's response. \n",
    "\n",
    "How does changing these new parameters change the model's behaviour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your solution here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are stuck or would like to check your answer you can: \n",
    "# Check Solutions/dynamic_threshold.py  \n",
    "\n",
    "# Or if you are running locally, you can:\n",
    "# Uncomment and run the line below to load the solution.\n",
    "# %load ./Solutions/dynamic_threshold.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model response\n",
    "v, spikes = neuron_model(I * scale) # simulate \n",
    "plot_model_response(I, v, spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "## Introduction\n",
    "Now we're going to see how well our model can approximate the spikes produced by a \"real\" neuron in response to a set of random input currents. Again, this \"real\" neuron is actually just a complex model, but the idea is the same! \n",
    "\n",
    "The data are split into **test** and **train** sets with three files each: \n",
    "* **Current** - the input currents that were injected into the neuron. A numpy array of shape repeats x time which we'll call ``I``.  \n",
    "\n",
    "* **Traces** - the membrane potential response to each input current. A numpy array of shape repeats x time which we'll call ``v``. \n",
    "\n",
    "* **Spikes** - contains two numpy vectors which we'll term: \n",
    "    * ``spike_times`` - the time of each spike (in ms).\n",
    "    * ``spike_idx`` - which repeat each spike comes from.\n",
    "\n",
    "In each data set there are: \n",
    "* **Train** - 100 repeats, with 10,000 time steps each.\n",
    "* **Test** - 50 repeats, with 10,000 time steps each. \n",
    "\n",
    "We'll start by plotting the first 10 repeats from the train set. Note that we'll normalise the data so we can plot several repeats per plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data  \n",
    "train_I = np.loadtxt('Data/train_current.csv') # shape (repeats, num_time_steps)\n",
    "train_v = np.loadtxt('Data/train_traces.csv') # shape (repeats, num_time_steps)\n",
    "train_spike_times, train_spike_idx = np.loadtxt('Data/train_spikes.csv') # shape (num_spikes,)\n",
    "\n",
    "repeats, num_time_steps = train_I.shape\n",
    "state_t = np.arange(num_time_steps)*0.1 # in ms\n",
    "\n",
    "def normalise(x):\n",
    "    return (x-x.min())/(x.max()-x.min())\n",
    "\n",
    "# Plotting\n",
    "for idx_repeat in range(10):\n",
    "    plt.plot(state_t, idx_repeat+0.9*normalise(train_I[idx_repeat, :]), color='xkcd:purple', label='Input current' if idx_repeat==0 else None)\n",
    "    plt.plot(state_t, idx_repeat+0.9*normalise(train_v[idx_repeat, :]), color='xkcd:dark seafoam green', label='Membrane potential' if idx_repeat==0 else None)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Repeat index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model\n",
    "\n",
    "Now we're going to test how well our model approximates this \"real\" neuron's spiking. \n",
    "\n",
    "To do so, we will:\n",
    "* Input the same currents to our model,\n",
    "* Record it's spikes. \n",
    "* Then compare our model's spikes to those from the \"real\" neuron.\n",
    "\n",
    "First, we'll do this **qualitatively**, by taking the first 10 input currents, and plotting both our model and the \"real\" neuron's spikes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_approximation(neuron_spike_times, neuron_spike_idx, input_I):\n",
    "    for idx_repeat in range(10):\n",
    "        model_v, model_spikes = neuron_model(input_I[idx_repeat]) # simulate \n",
    "        neuron_spikes = neuron_spike_times[neuron_spike_idx==idx_repeat] # get \"real\" spikes \n",
    "\n",
    "        plt.scatter(model_spikes, idx_repeat*np.ones(len(model_spikes)), marker='.', color='xkcd:dark seafoam green', label='Neuron model' if idx_repeat==0 else None)\n",
    "        plt.scatter(neuron_spikes, idx_repeat*np.ones(len(neuron_spikes))+0.2, marker='.', color='xkcd:purple', label='\"Real\" neuron' if idx_repeat==0 else None)\n",
    "\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('Repeat')\n",
    "    plt.legend()\n",
    "\n",
    "plot_approximation(train_spike_times, train_spike_idx, train_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll now compare our model **quantitively** to the \"real\" neuron.\n",
    "\n",
    "To do so we'll measure the [van Rossum distance](http://www.scholarpedia.org/article/Measures_of_spike_train_synchrony#van_Rossum_distance) between the spike trains from each using a pair of functions: \n",
    "\n",
    " ``van_rossum_distance`` - returns the distance between two spike trains ``t0`` and ``t1`` over a given ``duration`` (all measured in ms).  \n",
    "\n",
    " ``mean_vr_distance`` - returns the mean distance between our model and the \"real\" neuron across our entire train or test set.\n",
    "\n",
    "Don't worry too much about this metric or these functions! All you need to know is that in our case a smaller van Rossum distance means a better match between a model and the \"real\" neuron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def van_rossum_distance(t0, t1, duration, tau_vr=5, dt=0.1): \n",
    "    # Note that tau_vr is not the same as the tau used in our neuron_model. \n",
    "    n = int(np.round(duration/dt))\n",
    "    x0 = np.zeros(n)\n",
    "    x1 = np.zeros(n)\n",
    "    for x, t in [(x0, t0), (x1, t1)]:\n",
    "        x[np.array(np.round(t/dt), dtype=int)] = 1\n",
    "    nk = int(np.round(3*tau_vr/dt))\n",
    "    if 2*nk+1>n:\n",
    "        nk = (n-1)//2\n",
    "    T = np.arange(-nk, nk+1)*dt\n",
    "    kernel = np.exp(-T/tau_vr)/tau_vr\n",
    "    for x in [x0, x1]:\n",
    "        x[:] = np.convolve(x, kernel, 'same')\n",
    "    return np.sqrt(np.sum((x0-x1)**2*dt)/tau_vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_vr_distance(neuron_spike_times, neuron_spike_idx, input_I, dt=0.1, plot_aprox=True):\n",
    "    duration=input_I.shape[1]*dt\n",
    "\n",
    "    # Convert (t,i) format to list\n",
    "    neuron_spikes, model_spikes = [], [] \n",
    "    for idx_repeat in range(input_I.shape[0]):\n",
    "\n",
    "        # \"Real\" neuron\n",
    "        n_spikes = neuron_spike_times[neuron_spike_idx==idx_repeat]\n",
    "        neuron_spikes.append(neuron_spike_times[neuron_spike_idx==idx_repeat])\n",
    "\n",
    "        # Model\n",
    "        model_v, m_spikes = neuron_model(input_I[idx_repeat], baseline=0.0, threshold=1.0, dt=0.1, r_timer=0.5, tau=5, thr_i=2, thr_tau=50) # simulate \n",
    "        model_spikes.append(m_spikes)\n",
    "\n",
    "        # Plotting \n",
    "        if (plot_aprox == True) & (idx_repeat < 10):\n",
    "            plt.scatter(m_spikes, idx_repeat*np.ones(len(m_spikes)), marker='.', color='xkcd:dark seafoam green', label='Neuron model' if idx_repeat==0 else None)\n",
    "            plt.scatter(n_spikes, idx_repeat*np.ones(len(n_spikes))+0.2, marker='.', color='xkcd:purple', label='\"Real\" neuron' if idx_repeat==0 else None)\n",
    "\n",
    "            plt.xlabel('Time (ms)')\n",
    "            plt.ylabel('Repeat')\n",
    "            plt.legend()\n",
    "\n",
    "    # Distance\n",
    "    d = 0\n",
    "    for t0, t1 in zip(neuron_spikes, model_spikes):\n",
    "        d += van_rossum_distance(t0, t1, duration, dt=dt)\n",
    "    d /= len(neuron_spikes)\n",
    "\n",
    "    if plot_aprox == True:\n",
    "        print(\"Distance: \" + str(d))\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = mean_vr_distance(train_spike_times, train_spike_idx, train_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition\n",
    "\n",
    "Finally, we're going to have a friendly **competition** to see which pair can best match the \"real\" neuron's data, using their own models. Then for the last 30mins of the session, each pair will summarise what they tried and there will be a small prize for the pair with the model which best approximates the \"real\" neuron.\n",
    "\n",
    "As a measure we'll use the mean van Rossum distance between the model and \"real\" neuron over the **test** set (using the ``mean_vr_distance`` function). Note that you should use the **train** data for model development, fitting etc.  \n",
    "\n",
    "You are free to try whatever you like - though here are some ideas to get you started! \n",
    "\n",
    "* **Fitting model parameters** - throughout we've introduced several parameters to our model, guessing or even fitting different values for these could improve our approximation. For example, earlier we multiplied ``I`` by ``scale`` - we could add this to the ``mean_vr_distance`` function and test how changing it's value changes the approximation.\n",
    "\n",
    "* **Improving the neuron model** - real neurons have many complexities which we have simplified or overlooked. Improving how we have modelled these, or even adding new features could improve our model. For example, we have modelled the refractory period by simply setting the membrane potential to a baseline value, when in fact it *hyperpolarises* - dipping below baseline before returning.       \n",
    "\n",
    "* **\"Non-neuron\" models** - in principle any model which accepts ``I`` and returns spikes could approximate our data. For example, you could train a recurrent neural network to do this.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data  \n",
    "test_I = np.loadtxt('Data/test_current.csv') # shape (repeats, num_time_steps)\n",
    "test_v = np.loadtxt('Data/test_traces.csv') # shape (repeats, num_time_steps)\n",
    "test_spike_times, test_spike_idx = np.loadtxt('Data/test_spikes.csv') # shape (num_spikes,)\n",
    "\n",
    "# Test model\n",
    "d = mean_vr_distance(test_spike_times, test_spike_idx, test_I)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Trend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
