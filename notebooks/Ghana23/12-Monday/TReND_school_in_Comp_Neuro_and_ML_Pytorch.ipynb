{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img align=\"left\" width=\"300\" src=\"https://drive.google.com/uc?id=1xhBJo9KKicDMw6HuOCZiRclX5DJb2g_J\">\n",
        "\n",
        "    \n",
        "# **Introduction to Pytorch for Beginners** \n",
        "## Computational Neuroscience and Machine Learning Basics <br> Accra, Ghana <br> 11-24 June, 2023"
      ],
      "metadata": {
        "id": "LAHAiruXydkb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Ipf6r64mgTpR"
      },
      "source": [
        "# Tutorial 1: PyTorch\n",
        "**Week 1, Day 1: Basics and PyTorch**\n",
        "\n",
        "<!-- **By TReND school in Comp Neuro and ML** -->\n",
        "\n",
        "\n",
        "__Content creators:__ \n",
        " - Ishaya, Jeremiah Ayock\n",
        " - Elizabeth Cornell Awuku\n",
        "\n",
        "<!-- __Content reviewers:__ Ishaya, Jeremiah Ayock\n",
        "\n",
        "__Content editors:__ Ishaya, Jeremiah Ayock\n",
        "\n",
        "__Production editors:__ Ishaya, Jeremiah Ayock -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "6x0I98WQgTpV"
      },
      "source": [
        "---\n",
        "# Learning Objective\n",
        "\n",
        "\n",
        "- Understand the fundamental concepts of PyTorch and its role in numerical computations and deep learning.\n",
        "\n",
        "- Gain proficiency in creating tensors, performing basic operations, and manipulating tensors using indexing, slicing, reshaping, and concatenation.\n",
        "\n",
        "- Learn about automatic differentiation and its importance in PyTorch for calculating gradients."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Takeaways:**\n",
        "\n",
        "At the end of the tutorial, it is expected that every participant should;   \n",
        "\n",
        "- Have a clear understanding of PyTorch and its significance in deep learning and numerical computations.  \n",
        "\n",
        "- Be proficient in creating tensors of different shapes and sizes and performing basic element-wise operations on them.\n",
        "\n",
        "- Have the ability to access and modify tensor elements using indexing and \n",
        "slicing operations.\n",
        "\n",
        "\n",
        "- Have the Knowledge of reshaping and concatenating tensors to accommodate various requirements.\n",
        "\n",
        "- Have familiarity with built-in mathematical functions for performing computations on tensors.\n",
        "\n",
        "- Be aware of automatic differentiation and its role in calculating gradients in PyTorch.\n",
        "\n",
        "<!-- - Access to additional resources, tutorials, and documentation to continue learning and exploring PyTorch independently. -->"
      ],
      "metadata": {
        "id": "g2cfwq-0tTsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial Outline"
      ],
      "metadata": {
        "id": "gl7ZwnEp5Nh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1. Introduction to PyTorch**\n",
        "\n",
        "What is PyTorch and its role in deep learning and numerical computations?  \n",
        "Advantages of PyTorch, such as its ease of use, dynamic computational graph, and Pythonic interface.\n",
        "\n",
        "Installation and setup of PyTorch, including installing the necessary dependencies."
      ],
      "metadata": {
        "id": "8AzeJzMB6JbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2. Tensors and Operations**\n",
        "\n",
        "1. Introduction to Tensors\n",
        "\n",
        "- Explanation of tensors as fundamental data structures in PyTorch, similar to arrays or matrices.\n",
        "- Understanding the concept of dimensions and shape of tensors.\n",
        "- Creating tensors of different shapes and sizes using PyTorch.\n",
        "\n",
        "2. Basic Tensor Operations\n",
        "\n",
        "- Performing basic element-wise operations on tensors, such as addition, subtraction, multiplication, and division.\n",
        "- Demonstrating broadcasting and its role in performing operations on tensors of different shapes.\n",
        "- Explaining the importance of data types in tensors and how to convert between different data types.\n",
        "\n",
        "3. Indexing and Slicing\n",
        "\n",
        "- Accessing specific elements, rows, or columns in tensors using indexing and slicing operations.\n",
        "- Demonstrating how to modify specific elements of tensors using indexing.\n",
        "- Highlighting the difference between indexing and slicing in PyTorch.\n",
        "\n",
        "4. Reshaping and Concatenating Tensors\n",
        "\n",
        "- Understanding tensor reshaping and its applications, such as flattening or changing the dimensions of tensors.\n",
        "- Demonstrating how to reshape tensors using the reshape and view functions.\n",
        "- Concatenating tensors along different dimensions using the cat or stack functions.\n",
        "\n",
        "5. Element-wise Mathematical Functions\n",
        "\n",
        "- Exploring built-in mathematical functions in PyTorch for element-wise operations on tensors, such as square root, exponential, logarithm, etc.\n",
        "- Applying these functions to tensors to perform mathematical computations.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Pjs8EdwLhzL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3. Automatic Differentiation (Autograd)**"
      ],
      "metadata": {
        "id": "d6vLjaBWNJGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 4. Resources and Next Steps (5 minutes)**\n",
        "\n",
        "Providing additional resources for further learning and practice with PyTorch.  \n",
        "Suggesting online tutorials, documentation, and beginner-friendly projects.  \n",
        "Encouraging students to explore PyTorch's community and support."
      ],
      "metadata": {
        "id": "WxNdTID86knI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 1. Introduction to PyTorch (5 minutes)**\n"
      ],
      "metadata": {
        "id": "RlJD2SFR6CAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**i. What is PyTorch?**\n",
        "\n",
        "\n",
        "_PyTorch_ is an open-source machine learning library for Python developed by Facebook's AI Research (FAIR) team.\n",
        "\n",
        "It provides a flexible and efficient framework for building and training deep learning models.  \n",
        "\n",
        "\n",
        "_PyTorch_ is widely used in academia and industry due to its dynamic computational graph, ease of use, and strong community support.  \n",
        "\n",
        "\n",
        "\n",
        "**ii. Role of PyTorch in deep learning and numerical computations**\n",
        "\n",
        "\n",
        "\n",
        "_PyTorch_ is specifically designed for deep learning tasks such as **image classification, natural language processing, and computer vision.**\n",
        "It offers a rich set of tools and functions for creating, training, and evaluating neural networks.\n",
        "PyTorch's tensor computations and automatic differentiation capabilities make it suitable for various numerical computations beyond deep learning.  \n",
        "\n",
        "\n",
        "\n",
        "**iii. Advantages of PyTorch**\n",
        "\n",
        "\n",
        "\n",
        "- **Dynamic computational graph:** \n",
        "\n",
        "PyTorch allows for dynamic graph construction, enabling more flexibility in model design and debugging.\n",
        "\n",
        "- **Pythonic interface:**\n",
        "\n",
        "PyTorch integrates well with Python, making it easy to write and debug code.\n",
        "GPU acceleration: PyTorch seamlessly supports GPU acceleration, enabling faster computations for training deep learning models.\n",
        "\n",
        "- **Strong community support:**\n",
        "\n",
        "PyTorch has a large and active community, providing extensive documentation, tutorials, and libraries.  \n",
        "\n",
        "\n",
        "\n",
        "**iv. Installation and setup of PyTorch.**\n",
        "\n",
        "- ``conda install -y pytorch torchvision -c pytorch ``\n",
        "- ``pip3 install torch torchvision``"
      ],
      "metadata": {
        "id": "zLxsIU_MiYcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 2. Tensors and Operations (50 minutes)**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XAxHbFwritP5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Introduction to Tensors (10 minutes)**"
      ],
      "metadata": {
        "id": "N-XtAYrL8q8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensors** are fundamental data structures that serve as the core building \n",
        "  blocks for handling numerical data. A tensor can be thought of as a generalization of arrays or matrices, capable of representing data in any number of dimensions. \n",
        "\n",
        "**Tensors** are the primary data structure used to store and manipulate data in PyTorch, making them essential for tasks like deep learning, scientific computing, and numerical analysis."
      ],
      "metadata": {
        "id": "2Yu2hjagHkI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tensor can be created using PyTorch's tensor class, and it represents a multi-dimensional array of elements. These elements can be of different data types, such as floating-point numbers, integers, or even booleans. \n",
        "\n",
        "The elements of a tensor are stored in contiguous memory, enabling efficient computation and operations on the data."
      ],
      "metadata": {
        "id": "9vStwzLwH89I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison to Arrays or Matrices**\n",
        "\n",
        "**Tensors** can be seen as a more powerful extension of arrays or matrices. While arrays and matrices are limited to representing data in two or fewer dimensions, tensors have no such restriction. Tensors can handle data of any dimensionality, making them more versatile for complex tasks.\n",
        "\n",
        "**Arrays** and **matrices** are commonly used in traditional numerical computing and linear algebra. They provide a way to represent and perform operations on vectors and matrices, but they lack the flexibility and functionality offered by tensors. \n",
        "\n",
        "**Tensors** can represent higher-dimensional data, such as multi-channel images, time-series data, or even high-dimensional feature vectors."
      ],
      "metadata": {
        "id": "YytNr0HLIUSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Characteristics of Tensors:**\n",
        "\n",
        "**Tensors** possess three key characteristics: _data storage, shape, and dimensionality_.\n",
        "\n",
        "**Data Storage:**\n",
        "\n",
        "Tensors store their data in contiguous memory, ensuring efficient memory access and computation. This contiguous storage enables fast element-wise operations and allows for seamless integration with hardware acceleration, such as GPUs, for accelerated computation.\n",
        "\n",
        "**Shape:**\n",
        "\n",
        "The shape of a tensor defines the size along each axis or dimension. It is represented as a tuple of integers. \n",
        "\n",
        "For example, a 2D tensor with shape (3, 4) represents a matrix with 3 rows and 4 columns. \n",
        "\n",
        "The shape of a tensor determines the arrangement and organization of its elements.\n",
        "\n",
        "**Dimensionality:**\n",
        "\n",
        "Tensors can have any number of dimensions or axes. This means they can represent scalars (0D), vectors (1D), matrices (2D), or even higher-dimensional arrays (3D or more). Each dimension of a tensor corresponds to a specific mode of variation or feature in the data it represents.\n",
        "\n",
        "Understanding these key characteristics of tensors data storage, shape, and dimensionality allows us to effectively manipulate and transform data in PyTorch."
      ],
      "metadata": {
        "id": "W3O8kD_EIUWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Dimensions play a crucial role in understanding tensors. They represent the different axes or modes of variation within a tensor. Each dimension provides a unique way to organize and access the data stored in a tensor.\n",
        "\n",
        "The shape of a tensor describes its size along each dimension. It is expressed as a tuple of integers, where each integer represents the length of the corresponding dimension. The shape of a tensor determines the number of elements it can hold and the operations that can be performed on it. -->\n",
        "\n",
        "\n",
        "let explore three common types of tensors: 1D, 2D, and 3D tensors to gain a better understanding,"
      ],
      "metadata": {
        "id": "YEkkIlCfIeNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PyTorch libraries\n",
        "import torch"
      ],
      "metadata": {
        "id": "ECanvCdoRaZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1D Tensors:**\n",
        "\n",
        "A 1D tensor, also known as a vector, has a single axis. It can be visualized as a list of values arranged in a single row or column.\n",
        "\n",
        "For example, consider a 1D tensor representing daily temperature values for Accra City throughout a week."
      ],
      "metadata": {
        "id": "elGscOM7IeWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The tensor has a shape of (7,), indicating that it has 7 elements in a single dimension.\n",
        "\n",
        "accra_weekly_temperature = torch.tensor([23.5, 24.1, 22.8, 26.3, 25.9, 24.7, 23.2])\n",
        "print(accra_weekly_temperature)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jrWm5dRKc5x",
        "outputId": "73b2af02-8771-42fe-d7e4-b145ead5647b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([23.5000, 24.1000, 22.8000, 26.3000, 25.9000, 24.7000, 23.2000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2D Tensors:**\n",
        "\n",
        "A 2D tensor, also called a matrix, has two axes: rows and columns. It can be thought of as a table or grid of values.   \n",
        "\n",
        "For instance, consider a 2D tensor representing a grayscale image with pixel intensities: . \n"
      ],
      "metadata": {
        "id": "cBEvAQ8HKPVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this case, the tensor has a shape of (2, 3), indicating 2 rows and 3 columns.\n",
        "img = torch.tensor([[0.2, 0.4, 0.1], [0.6, 0.8, 0.3]])\n",
        "print(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wpQ2mh7K8F1",
        "outputId": "f994e2e5-7d23-44d1-b433-a426aeefab42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2000, 0.4000, 0.1000],\n",
            "        [0.6000, 0.8000, 0.3000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3D Tensors:**\n",
        "\n",
        "A 3D tensor adds depth as the third dimension to represent volumetric or sequential data. For example, imagine a 3D tensor representing a batch of RGB images: "
      ],
      "metadata": {
        "id": "rYHMAJciKSKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This tensor has a shape of (2, 2, 3), indicating 2 images, each with 2 rows and 3 columns of RGB values.\n",
        "\n",
        "col_img = torch.tensor([[[0.1, 0.3, 0.5], [0.4, 0.2, 0.9]], [[0.7, 0.6, 0.2], [0.3, 0.5, 0.8]]])\n",
        "print(col_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftO6aDqzLpP2",
        "outputId": "3a5fd4a7-91ab-4398-e298-46296cb37c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.1000, 0.3000, 0.5000],\n",
            "         [0.4000, 0.2000, 0.9000]],\n",
            "\n",
            "        [[0.7000, 0.6000, 0.2000],\n",
            "         [0.3000, 0.5000, 0.8000]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape and dimensions of a tensor play a significant role in determining the operations that can be performed on it. \n",
        "\n",
        "Tensor operations, such as element-wise additions, matrix multiplications, or convolutions, depend on compatible shapes and dimensions. \n",
        "\n",
        "Broadcasting, a feature of tensors, allows operations to be applied efficiently across tensors with different shapes by automatically aligning dimensions."
      ],
      "metadata": {
        "id": "tONcUJ78KWQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Tensors in PyTorch:\n"
      ],
      "metadata": {
        "id": "fG34cGZ5MEqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create tensors in PyTorch, we will walk through the following steps:"
      ],
      "metadata": {
        "id": "N3VRtiFMNrEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Importing the necessary libraries and setting up the environment.**\n",
        "\n",
        "Before creating tensors, it's essential to import the PyTorch library and set up the environment."
      ],
      "metadata": {
        "id": "LmvWb26aNyCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Creating tensors from Python lists or arrays.**\n",
        "\n",
        "We can create tensors by converting Python lists or arrays using the torch.``tensor()`` function."
      ],
      "metadata": {
        "id": "hFf8FHZHN8GQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a 1D tensor from a Python list\n",
        "my_list = [1, 2, 3, 4, 5]\n",
        "tensor_from_list = torch.tensor(my_list)\n",
        "print(tensor_from_list, '\\n')\n",
        "\n",
        "# Creating a 2D tensor from a Python nested list\n",
        "my_nested_list = [[1, 2, 3], [4, 5, 6]]\n",
        "tensor_from_nested_list = torch.tensor(my_nested_list)\n",
        "print(tensor_from_nested_list)\n"
      ],
      "metadata": {
        "id": "6Y9xsFJD9Fgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89fb439a-016b-4eb3-987b-da04aab74053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5]) \n",
            "\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Specifying the data type of tensors.**\n",
        "\n",
        "By default, tensors are created with the data type inferred from the input. However, we can also explicitly specify the data type using the ``dtype `` parameter."
      ],
      "metadata": {
        "id": "oDB0ZgfoOH9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor with a specific data type\n",
        "\n",
        "my_list = [1, 2, 3, 4, 5]\n",
        "tensor_with_dtype = torch.tensor(my_list, dtype=torch.float32)\n",
        "\n",
        "print(tensor_with_dtype)"
      ],
      "metadata": {
        "id": "0ccMO6pa9FjC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebcd6ea5-34e6-4f48-c1be-a0230f9f0018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4., 5.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Creating tensors of different shapes using PyTorch functions.**\n",
        "\n",
        "PyTorch provides several functions to create tensors of different shapes and fill them with specific values:"
      ],
      "metadata": {
        "id": "WcmC0bRlOS9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor filled with zeros\n",
        "zeros_tensor = torch.zeros((2, 3))\n",
        "print(\"Tensors filled with Zeros : \", zeros_tensor, '\\n')\n",
        "\n",
        "# Creating a tensor filled with ones\n",
        "ones_tensor = torch.ones((3, 2))\n",
        "print(\"Tensors filled with ones : \", ones_tensor, '\\n')\n",
        "\n",
        "# Creating a tensor with random values between 0 and 1\n",
        "random_tensor = torch.rand((3, 3))\n",
        "print(\"Tensors with random values between 0 and 1 : \", random_tensor, '\\n')\n",
        "\n",
        "\n",
        "# Creating a tensor with random values from a standard normal distribution\n",
        "normal_tensor = torch.randn((2, 2))\n",
        "print(\"Tensors with random values from a standard normal distribution : \", normal_tensor, '\\n')\n",
        "\n",
        "\n",
        "# Creating an uninitialized tensor\n",
        "empty_tensor = torch.empty((2, 2))\n",
        "print(\"uninitialized tensor : \", empty_tensor, '\\n')\n",
        "\n",
        "\n",
        "# Creating a tensor from existing data\n",
        "existing_data = [1, 2, 3, 4, 5]\n",
        "tensor_from_data = torch.tensor(existing_data)\n",
        "print(\"Tensors filled with ones : \", tensor_from_data)"
      ],
      "metadata": {
        "id": "HZIURRdCOP5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ba6e1a-a992-4469-8f41-142af0289eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensors filled with Zeros :  tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]]) \n",
            "\n",
            "Tensors filled with ones :  tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]]) \n",
            "\n",
            "Tensors with random values between 0 and 1 :  tensor([[0.6927, 0.6970, 0.1688],\n",
            "        [0.5186, 0.0222, 0.9901],\n",
            "        [0.2285, 0.8236, 0.9721]]) \n",
            "\n",
            "Tensors with random values from a standard normal distribution :  tensor([[-1.2131,  1.8832],\n",
            "        [ 0.7087,  2.1228]]) \n",
            "\n",
            "uninitialized tensor :  tensor([[-4.0045e-17,  4.5607e-41],\n",
            "        [ 1.4492e-34,  0.0000e+00]]) \n",
            "\n",
            "Tensors filled with ones :  tensor([1, 2, 3, 4, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Accessing and modifying tensor elements.**\n",
        "\n",
        "You can access and modify specific elements of a tensor using indexing and slicing, similar to Python lists or arrays."
      ],
      "metadata": {
        "id": "-6SDhFW6OZ6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing tensor elements\n",
        "my_tensor = torch.tensor([1, 2, 3, 4, 5])\n",
        "element = my_tensor[0]  # Accessing the first element\n",
        "print(\" The first element is : \", element, '\\n')\n",
        "\n",
        "# Modifying elements in tensor \n",
        "my_tensor[1] = 10  # modifying the second element\n",
        "print(\" The new tensor is : \", my_tensor)"
      ],
      "metadata": {
        "id": "XqzWXIfPOP8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98158502-9685-441f-f5f9-965167f9ef19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The first element is :  tensor(1) \n",
            "\n",
            " The new tensor is :  tensor([ 1, 10,  3,  4,  5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Visualizing tensors using matplotlib or other visualization libraries.**\n",
        "\n",
        "To visualize tensors, you can use libraries like matplotlib to plot or display them."
      ],
      "metadata": {
        "id": "f6XzduHYOiTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing a tensor\n",
        "my_tensor = torch.tensor([1, 2, 3, 4, 5]) # y axis\n",
        "plt.plot(my_tensor)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "eCaUq2ffOP-s",
        "outputId": "8e87b99d-8649-4496-9644-3dd4d87d3a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Basic Tensor Operations**"
      ],
      "metadata": {
        "id": "nshNe89f84qS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These operations include performing element-wise operations like addition, subtraction, multiplication, and division on tensors. \n",
        "\n",
        "We will also cover the concept of broadcasting, which allows operations to be performed on tensors of different shapes. \n",
        "\n",
        "\n",
        "We will also discuss the importance of data types in tensors and learn how to convert between different data types."
      ],
      "metadata": {
        "id": "8pdbaARRQ4EA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Element-wise Operations on Tensors:**\n",
        "\n",
        "\n",
        "\n",
        "Element-wise operations involve performing an operation between corresponding \n",
        "elements of two or more tensors. \n",
        "\n",
        "PyTorch provides operators such as `+` for addition, `-` for subtraction, `*` for multiplication, and `/` for division to perform these operations."
      ],
      "metadata": {
        "id": "NbLQZNVfQ_wX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.tensor([1, 2, 3])\n",
        "tensor2 = torch.tensor([4, 5, 6])\n",
        "\n",
        "# Element-wise addition\n",
        "addition_result = tensor1 + tensor2\n",
        "print(\"Element-wise addition : \", addition_result, '\\n') \n",
        "\n",
        "# Element-wise multiplication\n",
        "multiplication_result = tensor1 * tensor2\n",
        "print(\"Element-wise multiplication : \", multiplication_result, '\\n') \n",
        "\n",
        "\n",
        "# Element-wise subtraction\n",
        "subtraction_result = tensor2 - tensor1\n",
        "print(\"Element-wise subtraction : \", subtraction_result, '\\n') \n",
        "\n",
        "\n",
        "# Element-wise division\n",
        "division_result = tensor2 / tensor1\n",
        "print(\"Element-wise division : \", division_result, '\\n') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09kIW5ir9G5a",
        "outputId": "15ef1f98-8bab-46ad-9263-8985aa7bce47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element-wise addition :  tensor([5, 7, 9]) \n",
            "\n",
            "Element-wise multiplication :  tensor([ 4, 10, 18]) \n",
            "\n",
            "Element-wise subtraction :  tensor([3, 3, 3]) \n",
            "\n",
            "Element-wise division :  tensor([4.0000, 2.5000, 2.0000]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Broadcasting:**\n",
        "\n",
        "Broadcasting allows operations to be performed on tensors of different shapes by automatically aligning their dimensions. \n",
        "\n",
        "This feature simplifies element-wise operations between tensors with compatible shapes."
      ],
      "metadata": {
        "id": "C-S0EOx5RY0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tensors\n",
        "tensor1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "tensor2 = torch.tensor([10, 20, 30])\n",
        "\n",
        "# Broadcasting and addition\n",
        "result = tensor1 + tensor2\n",
        "\n",
        "# Displaying the result\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCeZLoI69G7c",
        "outputId": "c0a2c932-8cc2-418b-fe5d-7671ab6ecf30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[11, 22, 33],\n",
            "        [14, 25, 36]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the example above, the tensor ``tensor2`` is broadcasted to match the shape of ``tensor1``, and element-wise addition is performed."
      ],
      "metadata": {
        "id": "MRbCHdQnSlpm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importance of Data Types and Type Conversion:**\n",
        "\n",
        "Data types in tensors determine the kind of data they can hold and impact the memory usage and computation performance. \n",
        "\n",
        "PyTorch allows easy conversion between different data types using the ``.to()`` method."
      ],
      "metadata": {
        "id": "LgM5sSNhSy9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Checking the data type\n",
        "print(\"The data type is : \", tensor.dtype, \"\\n\") \n",
        "\n",
        "# Converting to float data type\n",
        "tensor_float = tensor.to(torch.float32)\n",
        "print(\"The data type is :\", tensor_float.dtype,\"\\n\") \n",
        "\n",
        "# Converting to boolean data type\n",
        "tensor_bool = tensor.to(torch.bool)\n",
        "print(\"The data type is : \", tensor_bool.dtype) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95zoKDit9G9k",
        "outputId": "b9e43fdb-2c86-44b3-c6f6-5b8319d4d69c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data type is :  torch.int64 \n",
            "\n",
            "The data type is : torch.float32 \n",
            "\n",
            "The data type is :  torch.bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using the ``.to()`` method, we can convert tensors to the desired data type, such as float or boolean."
      ],
      "metadata": {
        "id": "vtHNSQRBTDw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CqxdL_gblG4V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coding Exercise 2.1: Creating Tensors\n",
        "\n",
        "1. Given two tensors A and B of the same shape, how would you perform element-wise addition of the tensors?\n",
        "\n",
        "2. If you have a tensor C and want to subtract a scalar value 5 from each element of C, how would you achieve this using element-wise operations?\n",
        "\n",
        "3. Suppose you have two tensors D and E with different shapes, but you want to multiply them element-wise. How can you perform this operation?\n",
        "\n",
        "4. Consider a tensor F with shape (3, 3) and another tensor G with shape (1, 3).How would you divide each element of F by the corresponding element of G?\n",
        "\n",
        "5. If you have a tensor H with shape (2, 2, 2) and want to calculate the square root of each element using an element-wise operation, how can you accomplish this?\n"
      ],
      "metadata": {
        "id": "o_Ki6KsxlHQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Indexing and Slicing**"
      ],
      "metadata": {
        "id": "jm6p6Dn489cB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will explore the indexing and slicing operations in PyTorch. These operations allow us to access specific elements, rows, or columns in tensors and modify them if needed. \n",
        "\n",
        "It is important to also understand the difference between indexing and slicing in PyTorch."
      ],
      "metadata": {
        "id": "QT6KmQIPUn5R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accessing Specific Elements with Indexing:**\n",
        "\n",
        "Indexing refers to accessing individual elements of a tensor using their indices. In PyTorch, indexing starts from 0, similar to Python lists or arrays.\n",
        "\n",
        "Its  follows a similar syntax to indexing in Python lists or arrays. We can use square brackets ``[]`` to access specific elements, rows, or columns of a tensor."
      ],
      "metadata": {
        "id": "ubOudpV_UtNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor\n",
        "tensor = torch.tensor([[1, 2, 3],\n",
        "                       [4, 5, 6],\n",
        "                       [7, 8, 9]])\n",
        "\n",
        "# Accessing a specific element\n",
        "element = tensor[0, 1]\n",
        "print(element) \n",
        "\n",
        "# Accessing a specific row\n",
        "row = tensor[1]\n",
        "print(row)\n",
        "\n",
        "# Accessing a specific column\n",
        "column = tensor[:, 2]\n",
        "print(column)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro1QGMEx9Ipf",
        "outputId": "43c614cf-e1e3-4651-ee21-baade996d611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2)\n",
            "tensor([4, 5, 6])\n",
            "tensor([3, 6, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Slicing Rows and Columns:**\n",
        "\n",
        "Slicing allows us to extract specific portions (rows, columns, or sub-tensors) from a tensor. \n",
        "\n",
        "The general syntax for slicing in PyTorch is ``[start:stop:step]``."
      ],
      "metadata": {
        "id": "XmI0-l-KUlq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a 2D tensor\n",
        "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# Slicing rows\n",
        "row_slice = tensor[1:3, :]   # Slicing the second and third rows\n",
        "print(\" Row Slice : \", row_slice, \"\\n\")\n",
        "\n",
        "# Slicing columns\n",
        "col_slice = tensor[:, 0:2]   # Slicing the first two columns\n",
        "print(\" Column Slice :\", col_slice)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm9NHJRk9Ir0",
        "outputId": "da3e5d1d-52cd-46c5-83a0-fb0d74f537e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Row Slice :  tensor([[4, 5, 6],\n",
            "        [7, 8, 9]]) \n",
            "\n",
            " Column Slice : tensor([[1, 2],\n",
            "        [4, 5],\n",
            "        [7, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modifying Specific Elements with Indexing:**\n",
        "\n",
        "We can use indexing to modify individual elements of a tensor"
      ],
      "metadata": {
        "id": "2bnSPSDvVEMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor\n",
        "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
        "\n",
        "# Modifying specific elements\n",
        "tensor[1] = 10 \n",
        "tensor[3] = 20\n",
        "\n",
        "# Displaying the modified tensor\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5MHKP9s9IuH",
        "outputId": "73f2940f-2f93-460a-cb90-7c3c596637ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1, 10,  3, 20,  5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Difference between Indexing and Slicing:**\n",
        "\n",
        "\n",
        "Indexing and slicing are similar in syntax but differ in their output.\n",
        "\n",
        "Indexing returns a scalar value (individual element) or a tensor with reduced dimensions, while slicing returns a sub-tensor with the same or reduced dimensions."
      ],
      "metadata": {
        "id": "OakW9KAXVQjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a 2D tensor\n",
        "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# Indexing returns a scalar\n",
        "element = tensor[1, 1]   # Accessing the element at row 1, column 1\n",
        "print(\" For indexing : \", element, \"\\n\") \n",
        "\n",
        "# Slicing returns a sub-tensor\n",
        "sub_tensor = tensor[0:2, :]   # Slicing the first two rows\n",
        "print(\" For Slicing : \", sub_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VyZtxHy9IwO",
        "outputId": "a6b764d6-aad3-4448-a75e-7c791fb1c764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " For indexing :  tensor(5) \n",
            "\n",
            " For Slicing :  tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding indexing and slicing operations in PyTorch is crucial for extracting and modifying specific elements or portions of tensors."
      ],
      "metadata": {
        "id": "6Njs9ctZVbMl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f8iTAB_N9JH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coding Exercise 3.1: Creating Tensors\n",
        "\n",
        "1. How can you extract the last three elements from a PyTorch tensor using indexing and slicing? Provide the code for this operation.\n",
        "\n",
        "2. Given a `2D` PyTorch tensor called tensor_2d, how can you extract the second column using slicing? Provide the code for this operation.\n",
        "\n",
        "3. Suppose you have a PyTorch tensor called tensor with shape `(5, 5, 3)`. How can you extract a `3x3` submatrix from the top-left corner of the tensor? Provide the code for this operation.\n",
        "\n",
        "4. Given a PyTorch tensor called tensor, how can you reverse the order of elements along the first dimension using slicing? Provide the code for this operation.\n",
        "\n",
        "5. Suppose you have a PyTorch tensor called tensor with shape `(3, 4, 5)`. How can you extract a sub-tensor containing the elements in the second row and third column of each 2D matrix along the first dimension? Provide the code for this operation. "
      ],
      "metadata": {
        "id": "yUMCGZCFog9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Reshaping and Concatenating Tensors**"
      ],
      "metadata": {
        "id": "hqaNPPUc9AFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will explore tensor reshaping and concatenation operations in PyTorch. \n",
        "\n",
        "Reshaping allows us to change the dimensions of tensors, such as flattening them or rearranging their shape. \n",
        "\n",
        "Concatenation enables us to combine tensors along different dimensions. We will demonstrate how to reshape tensors using the ``reshape`` and ``view`` functions and concatenate tensors using the ``cat`` and ``stack`` functions."
      ],
      "metadata": {
        "id": "awoVJafOIe5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reshaping Tensors:**\n",
        "\n",
        "Reshaping tensors is useful when we want to change their dimensions or rearrange the elements. \n",
        "\n",
        "PyTorch provides two functions, ``reshape()`` and ``view()``, to reshape tensors."
      ],
      "metadata": {
        "id": "p0WjR-xGJTPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor\n",
        "tensor = torch.tensor([[1, 2, 3],\n",
        "                       [4, 5, 6]])\n",
        "\n",
        "# Reshaping using reshape function\n",
        "reshaped_tensor = tensor.reshape(6)\n",
        "print(reshaped_tensor)\n",
        "\n",
        "# Reshaping using view function\n",
        "viewed_tensor = tensor.view(3, 2)\n",
        "print(viewed_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rda_5QnT9KHh",
        "outputId": "c19db51f-590b-4e2e-ad39-aa3f5e04f5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6])\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the example above, we reshape the tensor to a 1D tensor using ``reshape()`` and change it back to a 2D tensor using ``view()``."
      ],
      "metadata": {
        "id": "676BO4aAJwe1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Concatenating Tensors:**\n",
        "\n",
        "Concatenating tensors allows us to combine multiple tensors along different dimensions. PyTorch provides the ``cat()`` and ``stack()`` functions for concatenation."
      ],
      "metadata": {
        "id": "ERopXvtpJ7aD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tensors\n",
        "tensor1 = torch.tensor([[1, 2],\n",
        "                        [3, 4]])\n",
        "tensor2 = torch.tensor([[5, 6],\n",
        "                        [7, 8]])\n",
        "\n",
        "\n",
        "# Concatenating along the rows (dimension 0) using cat()\n",
        "concatenated_rows = torch.cat((tensor1, tensor2), dim=0)\n",
        "print(\"concatenated along rows : \", concatenated_rows, \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# Concatenating along the columns (dimension 1) using cat()\n",
        "concatenated_columns = torch.cat((tensor1, tensor2), dim=1)\n",
        "print(\"concatenated along columns : \", concatenated_columns, \"\\n\")\n",
        "\n",
        "\n",
        "# Stacking tensors along a new dimension using the stack()\n",
        "stacked_tensor = torch.stack((tensor1, tensor2))\n",
        "print(\"stacked tensors : \", stacked_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVUop3Pu9KJ8",
        "outputId": "8e2d779e-0c28-49fb-d9b0-8917767e21d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "concatenated along rows :  tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6],\n",
            "        [7, 8]]) \n",
            "\n",
            "concatenated along columns :  tensor([[1, 2, 5, 6],\n",
            "        [3, 4, 7, 8]]) \n",
            "\n",
            "stacked tensors :  tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ``cat()`` function in the above example is used to concatenate tensors along dimension 0 and dimension 1, while ``stack()`` function is used to stack the tensors along a new dimension (dimension 0)."
      ],
      "metadata": {
        "id": "1ToYUFaRKMIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coding Exercise 4.1: Creating Tensors\n",
        "\n",
        "\n",
        "1. Given two tensors t1 and t2, concatenates these tensors along dimension 0.\n",
        "2. Given that i have two torch tensors. One with shape [64, 4, 300], and one with shape [64, 300]. How can I concatenate these two tensors to obtain the resultant tensor of shape [64, 5, 300]. \n",
        "\n",
        "3. Given a tensor with the following element  `[1, 2, 3, 4, 5, 6, 7, 8]`, How can you reshape it.\n",
        "4. What is the difference between `torch.cat` and ``torch.concat`. "
      ],
      "metadata": {
        "id": "x0n9DCKJp2TZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Element-wise Mathematical Functions**"
      ],
      "metadata": {
        "id": "21xa09gL9CMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will explore the built-in mathematical functions in PyTorch that operate element-wise on tensors. These functions allow us to perform various mathematical computations on tensors, such as calculating the square root, exponential, logarithm, and more."
      ],
      "metadata": {
        "id": "sgs4kPIlLqHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Square Root Function:**\n",
        "\n",
        "The `torch.sqrt()` function computes the square root of each element in a tensor."
      ],
      "metadata": {
        "id": "JLZ9yQTjN2au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor\n",
        "tensor = torch.tensor([4, 9, 16])\n",
        "\n",
        "# Square root function\n",
        "sqrt_tensor = torch.sqrt(tensor)\n",
        "print(sqrt_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px_qhm0HNC6_",
        "outputId": "fc3cc4bf-80c4-48a6-8fb1-b014aaaaa450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 3., 4.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The square root of each element in the tensor is calculated using the `torch.sqrt()` function."
      ],
      "metadata": {
        "id": "FVpa1M_bOCyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exponential Function:**\n",
        "\n",
        "The `torch.exp()` function calculates the exponential value of each element in a tensor."
      ],
      "metadata": {
        "id": "0A_G8LdVOLd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "\n",
        "# Exponential function\n",
        "exp_tensor = torch.exp(tensor)\n",
        "print(exp_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6UbYAFCNC-N",
        "outputId": "1068a303-df1c-4d8e-b5ee-71243b8e917d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2.7183,  7.3891, 20.0855])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logarithmic Functions:**\n",
        "\n",
        "PyTorch provides two logarithmic functions: `torch.log()` for natural logarithm and `torch.log10()` for base 10 logarithm."
      ],
      "metadata": {
        "id": "9_1TxayyOZMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor\n",
        "tensor = torch.tensor([1, 10, 100])\n",
        "\n",
        "# Natural logarithm function\n",
        "log_tensor = torch.log(tensor)\n",
        "print(log_tensor)\n",
        "\n",
        "# Base 10 logarithm function\n",
        "log10_tensor = torch.log10(tensor)\n",
        "print(log10_tensor)"
      ],
      "metadata": {
        "id": "TCd1oRgMNDDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12fe7057-6a13-4ad7-ef25-3f50278b80a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0000, 2.3026, 4.6052])\n",
            "tensor([0., 1., 2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the example above, both natural logarithm and base 10 logarithm functions are applied to each element of the tensor using `torch.log()` and `torch.log10()` respectively."
      ],
      "metadata": {
        "id": "BstvUXlfOjaB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trigonometric Functions:**\n",
        "\n",
        "PyTorch provides various trigonometric functions that can be applied element-wise to tensors. Let's take a look at a few examples:"
      ],
      "metadata": {
        "id": "QbjlhHcmO3zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "# Creating a tensor\n",
        "tensor = torch.tensor([0, math.pi/4, math.pi/2])\n",
        "\n",
        "# Sine function\n",
        "sin_tensor = torch.sin(tensor)\n",
        "print(\"Sine function : \", sin_tensor,\"\\n\")\n",
        "\n",
        "# Cosine function\n",
        "cos_tensor = torch.cos(tensor)\n",
        "print(\"Cosine function : \", cos_tensor,\"\\n\")\n",
        "\n",
        "# Tangent function\n",
        "tan_tensor = torch.tan(tensor)\n",
        "print(\"Tangent function : \", tan_tensor, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jewB7w9ANDeW",
        "outputId": "cad55b1c-5486-4131-d86d-a47d52e1f48b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sine function :  tensor([0.0000, 0.7071, 1.0000]) \n",
            "\n",
            "Cosine function :  tensor([ 1.0000e+00,  7.0711e-01, -4.3711e-08]) \n",
            "\n",
            "Tangent function :  tensor([ 0.0000e+00,  1.0000e+00, -2.2877e+07]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the example above, the sine, cosine, and tangent functions (`torch.sin()`, `torch.cos()`, `torch.tan()`) are applied to each element of the tensor.\n"
      ],
      "metadata": {
        "id": "pOWWEI8NLqLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Absolute Function:**\n",
        "\n",
        "The `torch.abs()` function computes the absolute value of each element in a tensor."
      ],
      "metadata": {
        "id": "O6tHgl8TLqP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor\n",
        "tensor = torch.tensor([-2, -5, 6])\n",
        "\n",
        "# Absolute function\n",
        "abs_tensor = torch.abs(tensor)\n",
        "print(abs_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD5q7c3C9MF0",
        "outputId": "6fc81a60-82b4-43ca-a402-2f0b99a1e87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 5, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coding Exercise 5.1: Creating Tensors \n",
        "\n",
        "1. Given a tensor with values [4, 9, 16, 25], calculate the square root of each element.\n",
        "\n",
        "2. Compute the exponential of the tensor [1, 2, 3] element-wise.\n",
        "\n",
        "3. Calculate the logarithm base 2 for a tensor with elements [8, 16, 32].\n",
        "\n",
        "4. Calculate the logarithm base 10 of the tensor [10, 100, 1000] element-wise.\n",
        "\n",
        "5. Evaluate the exponential function for a tensor element-wise using base e for the tensor [1, 2, 3]."
      ],
      "metadata": {
        "id": "aTarYOTqsGUx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above example, the absolute value of each element in the tensor is calculated using the `torch.abs()` function"
      ],
      "metadata": {
        "id": "eI3Hn5sDPoaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 3. Automatic Differentiation (Autograd)**"
      ],
      "metadata": {
        "id": "_KMpD7OCZ6Ef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch so powerful for deep learning development.   \n",
        "The **backward()** method/function uses PyTorch's automatic differentiation.  package, `torch.autograd`,   \n",
        "to differentiate and compute gradients of tensors based on the chain rule."
      ],
      "metadata": {
        "id": "nLgmYb9ge6-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. PyTorch Computational Graphs:**\n",
        "\n",
        "PyTorch defines a computational graph as a **Directed Acyclic Graph (DAG)** where nodes represent operations (e.g., addition, multiplication) and edges represent the flow of data between the operations. When defining a PyTorch model, the computational graph is created by defining the forward function of the model. This function takes inputs and applies a sequence of operations to produce the outputs. During the forward pass, PyTorch creates the computational graph by keeping track of the operations and their dependencies.\n",
        "\n",
        "**2. Autograd in PyTorch:**\n",
        "\n",
        "PyTorch's autograd package provides automatic differentiation functionality, which is crucial for computing gradients in neural networks. The autograd package keeps track of operations performed on tensors and dynamically builds the computational graph. It enables efficient computation of gradients using the chain rule of calculus. When a tensor with `requires_grad=True `undergoes operations, the computational graph is constructed and allows backpropagation to compute gradients for the parameters involved in the graph.\n",
        "\n",
        "\n",
        "\n",
        "**3. Execution of Computational Graphs:**\n",
        "\n",
        "PyTorch executes the computational graph in a two-step process: **the forward pass and the backward pass**. In the forward pass, input tensors flow through the computational graph, and intermediate values are computed until the final output is obtained. During this process, PyTorch keeps track of operations and tensors involved for gradient computation in the backward pass. In the backward pass, gradients are computed by traversing the computational graph in reverse order, starting from the output and propagating gradients using the chain rule. These gradients can then be used for updating the model parameters through optimization algorithms.\n",
        "\n",
        "\n",
        "For example\n",
        "$$w = x\\cdot y \\rightarrow \\frac{dw}{dx} = y = 3$$"
      ],
      "metadata": {
        "id": "kGiyH9_kecbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensors with requires_grad=True to track the computation\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = torch.tensor(3.0, requires_grad=True)\n",
        "\n",
        "# This performs some computations\n",
        "z = x + y\n",
        "w = z * y\n",
        "\n",
        "# This Calculate the gradients using the .backward() method\n",
        "w.backward()\n",
        "\n",
        "# Print the gradients\n",
        "print(\"Gradient of w with respect to x:\", x.grad)\n",
        "print(\"Gradient of w with respect to y:\", y.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ijtewb7wgzPb",
        "outputId": "ce7108e9-2247-43c1-c7ce-027b2b774515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of w with respect to x: tensor(3.)\n",
            "Gradient of w with respect to y: tensor(8.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We created two tensors `x` and `y` with `requires_grad=True` to indicate that we want to track the computation for calculating gradients.  \n",
        "\n",
        "Then we perform some computations: `z = x + y` and `w = z * y`.\n",
        "After that, the `.backward()` method was called on `w `to initiate the backpropagation process and calculate the gradients. \n",
        "\n",
        "Finally, we print The gradients of` w` with respect to `x` and `y` were printed using using the `.grad` attribute of the tensors.\n"
      ],
      "metadata": {
        "id": "jUhwU0UshWOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mathematically\n",
        "\n",
        "$$z = x+y$$, $$w = z * y$$   \n",
        "$$w = ( x + y)* y $$. \n",
        "$$w = xy + y^2 $$\n",
        "\n",
        "$$ \\frac{dw}{dx} = y $$ \n",
        "\n",
        "$$ \\frac{dw}{dy} = x + 2y $$ "
      ],
      "metadata": {
        "id": "eoKvM-08mLLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example of autodifferentiation.** \n",
        "\n",
        "Let  define a function,$$f= \\sum_{i,j} [x_{ij}]^3$$, where `x` is a matrix of variables.   \n",
        "If we want to find $$\\frac{df}{dx_{ij}}$$ for each variable in the matrix, we need to set the `requires_grad = True`\n",
        "flag for the tensor `x`, as shown in the following code:"
      ],
      "metadata": {
        "id": "KEPy7OilaKnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1,2,3],[4,5,6]],\n",
        "                 dtype=torch.float, \n",
        "                 requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K_tbd9SbQNo",
        "outputId": "3ae5a8e2-43fa-4260-b8cf-6e0bf49db160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = x.pow(3).sum()\n",
        "print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtrRg8QDLCjw",
        "outputId": "182c1f8b-a367-4be7-ef26-5d3e3e43fd85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(441., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f.backward()\n",
        "print(x.grad) # df/dx = 3x "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC5Gs7ttdIn2",
        "outputId": "be4611c5-0ad4-4644-d992-65b8ea992822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  3.,  12.,  27.],\n",
            "        [ 48.,  75., 108.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `f.backward()` function performs the differentiation with respect to `f` and stores $$\\frac{df}{dx_{ij}}$$ in the `x.grad` attribute. \n",
        "\n",
        "A quick review of calculus differential equations will tell us the derivation of `f` with respect to `x`, $$\\frac{df}{dx_{ij}} = 3  x^2$$.   \n",
        "The results of evaluating $$\\frac{df}{dx_{ij}}$$ for the values of `x `are shown as the output."
      ],
      "metadata": {
        "id": "7hytCZ5KaKzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 4. Resources and Next Steps (5 minutes)**\n",
        "\n",
        "## Official PyTorch resources:\n",
        "\n",
        "### Tutorials\n",
        "- [https://pytorch.org/tutorials/](https://pytorch.org/tutorials/)\n",
        "\n",
        "### Documentation\n",
        "- [https://pytorch.org/docs/stable/tensors.html](https://pytorch.org/docs/stable/tensors.html) (tensor methods)\n",
        "\n",
        "- [https://pytorch.org/docs/stable/generated/torch.Tensor.view.html#torch.Tensor.view](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html#torch.Tensor.view) (The view method in particular)\n",
        "\n",
        "- [https://pytorch.org/vision/stable/datasets.html](https://pytorch.org/vision/stable/datasets.html) (pre-loaded image datasets)"
      ],
      "metadata": {
        "id": "X2Muim7mUKB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "5eOZI136174R"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zpPYOXeHDdPR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}